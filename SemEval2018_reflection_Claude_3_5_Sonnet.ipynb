{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "KcvE4KCqs1Hb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcvE4KCqs1Hb",
    "outputId": "d38f9a35-da02-4c0b-ffd2-5565dfb82db7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: openai in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (1.52.1)\n",
      "Requirement already satisfied: together in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (1.3.3)\n",
      "Requirement already satisfied: anthropic in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (0.37.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from together) (3.10.10)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from together) (8.1.7)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from together) (0.2.0)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from together) (3.16.1)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from together) (10.4.0)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from together) (17.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from together) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from together) (13.9.3)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from together) (0.9.0)\n",
      "Requirement already satisfied: typer<0.13,>=0.9 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from together) (0.12.5)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from anthropic) (0.20.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/opt/certifi/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->together) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->together) (2.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from tokenizers>=0.13.0->anthropic) (0.26.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from typer<0.13,>=0.9->together) (1.5.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.9.3->together) (0.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas openai together anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e1045e13-3cba-441f-bf34-18b11d3646e0",
   "metadata": {
    "id": "e1045e13-3cba-441f-bf34-18b11d3646e0"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import random\n",
    "import anthropic\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62d219a1-6872-4ff1-be2c-eabeba850b08",
   "metadata": {
    "id": "62d219a1-6872-4ff1-be2c-eabeba850b08"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "136e5a33-6f84-4039-9738-c4b7d9e33f4d",
   "metadata": {
    "id": "136e5a33-6f84-4039-9738-c4b7d9e33f4d"
   },
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "path = \"../data/iSarcasmEval.csv\"\n",
    "df = pd.read_csv(path);\n",
    "\n",
    "answers = df['sarcastic']\n",
    "statements = df['tweet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "99fe05e7",
   "metadata": {
    "id": "99fe05e7"
   },
   "outputs": [],
   "source": [
    "outputs =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9d1e110-87dc-493b-8aa3-0bccbc1a6058",
   "metadata": {
    "id": "b9d1e110-87dc-493b-8aa3-0bccbc1a6058"
   },
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "\n",
    "def getResultNoPrompt(input, answer):\n",
    "    anthropic = Anthropic()\n",
    "\n",
    "    prompt = f\"\\\"{input}\\\"\\n Determine whether this statement is sarcastic with YES or NO.\"\n",
    "\n",
    "    response = anthropic.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=3000,\n",
    "        temperature=1.0\n",
    "    )\n",
    "\n",
    "    output = response.content[0].text.strip()\n",
    "    isSarcastic = True if \"yes\" in output.lower() else False\n",
    "    return isSarcastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "41560bb2-bba6-42ce-9312-92c02dc167e3",
   "metadata": {
    "id": "41560bb2-bba6-42ce-9312-92c02dc167e3"
   },
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "\n",
    "def getResultWPrompt(sample_input):\n",
    "   anthropic = Anthropic()\n",
    "   judgeInput = \"\"\n",
    "   output = \"\"\n",
    "\n",
    "   # System prompt for sarcasm justification\n",
    "   sarc_system_prompt = (\"You will be given a message from a political debate on the internet, and will analyze the statement. Repeat back the statement to analyze.\"\n",
    "                        \"Then, analyze the following:\\n\"\n",
    "                        \"-What does the speaker imply about the situation with their statement?\\n\"\n",
    "                        \"-What does the speaker think about the situation?\\n\"\n",
    "                        \"-Are what the speaker implies and what the speaker thinks saying the same thing?\\n\"\n",
    "                        \"Finally, decide if the speaker is pretending to have a certain attitude toward the conversation.\"\n",
    "                       )\n",
    "\n",
    "   sarc_response = anthropic.messages.create(\n",
    "       model=\"claude-3-5-sonnet-20240620\",\n",
    "       system=sarc_system_prompt,\n",
    "       messages=[\n",
    "           {\"role\": \"user\", \"content\": sample_input}\n",
    "       ],\n",
    "       max_tokens=2000,\n",
    "       temperature=1.0\n",
    "   )\n",
    "\n",
    "   judgeInput += \"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - \\n\"\n",
    "   judgeInput += sarc_response.content[0].text.strip()\n",
    "\n",
    "   reflect_system_prompt = (\"You will be given a message from a political debate on the internet and a preliminary analysis on the statement. Summarize the preliminary analysis\"\n",
    "                          \"Decide whether statement is sarcastic or not by first analyzing the following:\\n\"\n",
    "                          \"\\nThe Implicature - What is implied in the conversation beyond the literal meaning?\"\n",
    "                          \"\\nThe Presuppositions - What information in the conversation is taken for granted?\"\n",
    "                          \"\\nThe intent of the speaker - What do the speaker(s) hope to achieve with their statement and who are the speakers?\\n\"\n",
    "                          \"\\nThe polarity - Does the last sentence have a positive or negative tone?\"\n",
    "                          \"\\nPretense - Is there pretense in the speaker's attitude?\"\n",
    "                          \"\\nMeaning- What is the difference between the literal and implied meaning of the statement?\"\n",
    "                          \"Reflect on the preliminary analysis and what should change, then decide if the statment is sarcastic.\")\n",
    "\n",
    "   reflection_response = anthropic.messages.create(\n",
    "       model=\"claude-3-5-sonnet-20240620\",\n",
    "       system=reflect_system_prompt,\n",
    "       messages=[\n",
    "           {\"role\": \"user\", \"content\": sample_input + \" \" + judgeInput}\n",
    "       ],\n",
    "       max_tokens=4000,\n",
    "       temperature=1.0\n",
    "   )\n",
    "\n",
    "   judgeInput += \"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - \\n\"\n",
    "   judgeInput += reflection_response.content[0].text.strip()\n",
    "   judgeInput += \"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - \\n\"\n",
    "   output += (f\"\\nANSWER: {judgeInput}\\n\")\n",
    "\n",
    "   # Clean output prompt to summarize the decision as YES/NO\n",
    "   clean_system_prompt = (\n",
    "       \"You will be given the output of an LLM which decided if a sentence is sarcastic or not. \"\n",
    "       \"Read the output, then summarize the LLM's stance with ONLY a YES (they think the sentence is sarcastic) or NO (they think the sentence is not sarcastic).\"\n",
    "   )\n",
    "\n",
    "   clean_output = anthropic.messages.create(\n",
    "       model=\"claude-3-5-sonnet-20240620\",\n",
    "       system=clean_system_prompt,\n",
    "       messages=[\n",
    "           {\"role\": \"user\", \"content\": judgeInput}\n",
    "       ],\n",
    "       max_tokens=10,\n",
    "       temperature=1.0\n",
    "   )\n",
    "\n",
    "   clean_output = clean_output.content[0].text.strip()\n",
    "   output += (f\"Judgement: {clean_output}\\n\")\n",
    "\n",
    "   # Store output and determine if the statement is sarcastic\n",
    "   outputs.append(output)  # Make sure 'outputs' is defined in your scope\n",
    "   isSarcastic = True if \"yes\" in clean_output.lower() else False\n",
    "   return isSarcastic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44773b51",
   "metadata": {
    "id": "44773b51"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3aed0c29-e06f-4676-8851-80e4a540825b",
   "metadata": {
    "id": "3aed0c29-e06f-4676-8851-80e4a540825b"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def beginPrompting(inputs, answers, with_prompt):#, indices):\n",
    "    num_samples = len(indices)\n",
    "\n",
    "    with open(\"SarcasmCorpus_mistakes_V1.txt\" ,\"a\") as file:\n",
    "            file.write (f\"\\nIncorrect Answers: (Full output listed below) \\n- - - - - - - - - - - - - - - - - - - - - - - - - - - \\n\")\n",
    "\n",
    "    # indices = random.sample(range(len(inputs)), num_samples)\n",
    "    # sampled_inputs = [inputs[i] for i in indices]\n",
    "    # sampled_answers = [answers[i] for i in indices]\n",
    "\n",
    "    isSarCt = 0\n",
    "    noSarCt = 0\n",
    "    totNoSarCt = 0\n",
    "    totSarCt = 0\n",
    "\n",
    "    # Changed all of the sampled_inputs to inputs and sampled_answers to answers\n",
    "    \n",
    "    for x in range(num_samples):\n",
    "        time.sleep(5)\n",
    "        isSarcastic = getResultWPrompt(inputs[x]) if with_prompt else getResultNoPrompt(inputs[x])\n",
    "        if answers[x] == 1:\n",
    "            totSarCt += 1\n",
    "            if(isSarcastic):\n",
    "                isSarCt += 1\n",
    "            else:\n",
    "                with open(\"SarcasmCorpus_mistakes_V1.txt\" ,\"a\") as file:\n",
    "                    file.write (f\"\\n{outputs[x]} \\n- - - - - - - - - - - - - - - - - - - - - - - - - - - \\n\")\n",
    "                    file.write (f\"\\nANSWER: {answers[x]}\\n\")\n",
    "        else:\n",
    "            totNoSarCt += 1\n",
    "            if(not isSarcastic):\n",
    "                noSarCt += 1\n",
    "            else:\n",
    "                with open(\"SarcasmCorpus_mistakes_V1.txt\" ,\"a\") as file:\n",
    "                    file.write (f\"\\n{outputs[x]} \\n- - - - - - - - - - - - - - - - - - - - - - - - - - - \\n\")\n",
    "                    file.write (f\"\\nANSWER: {sampled_answers[x]}\\n\")\n",
    "        if with_prompt:\n",
    "            outputs[x]+=(f\"\\nANSWER: {sampled_answers[x]}\\n\")\n",
    "            outputs[x]+=(f\"Prompt sarcastic statement recognition ({isSarCt} total)\\n\")\n",
    "            outputs[x]+=(f\"Total Prompted sarcastic statement  ({totSarCt} total)  \\n\")\n",
    "            outputs[x]+=(f\"Non sarcastic statement recognition ({noSarCt} total)\\n\")\n",
    "            outputs[x]+=(f\"Total Prompted non sarcastic statement ({totNoSarCt} total)\\n\")\n",
    "    sar_percentage = (isSarCt / totSarCt * 100) if totSarCt > 0 else 0\n",
    "    no_sar_percentage = (noSarCt / totNoSarCt * 100) if totNoSarCt > 0 else 0\n",
    "\n",
    "    return sar_percentage, no_sar_percentage, totSarCt, totNoSarCt, noSarCt, isSarCt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "75b5f647-b82c-4aa0-a56f-7b651a7847c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "75b5f647-b82c-4aa0-a56f-7b651a7847c8",
    "outputId": "9db404e1-67b7-48cc-9419-5cfa4f296303",
    "scrolled": true
   },
   "source": [
    "sar_percentage_prompted, no_sar_percentage_prompted, total_sar, total_no_sar, noSarCT, isSarCT = beginPrompting(statements,answers, True, indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9437ad67-7a8e-479b-a94a-ed8e908c7392",
   "metadata": {
    "id": "9437ad67-7a8e-479b-a94a-ed8e908c7392"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "# Format the date and time as a string\n",
    "formatted_datetime = now.strftime(\"%m-%d-%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f7651842-1f74-40b5-8e4c-2a5a5a6e9179",
   "metadata": {
    "id": "f7651842-1f74-40b5-8e4c-2a5a5a6e9179"
   },
   "outputs": [],
   "source": [
    "with open(\"SemEval2018_V1.txt\", \"a\") as file:\n",
    "    file.write(f\"\\nSarcasm Corpus V1 ({formatted_datetime}, Total Sample Size : {sampleSize}): \\n\")\n",
    "    file.write(f\"Prompted sarcastic statement recognition ({total_sar} total) : {sar_percentage_prompted}% \\n\")\n",
    "    file.write(f\"Total correct: {isSarCT}\\n\")\n",
    "    file.write(f\"Prompted non sarcastic statement recognition ({total_no_sar} total) : {no_sar_percentage_prompted}%\\n\")\n",
    "    file.write(f\"Total correct: {noSarCT}\\n\")\n",
    "    # file.write(f\"No prompt sarcastic statement recognition ({total_sar_no_prompt} total) : {sar_percentage_base}%\\n\")\n",
    "    # file.write(f\"Total correct: {zeroIsSarCT}\")\n",
    "    # file.write(f\"No prompt non sarcastic statement recognition ({total_no_sar_no_prompt} total) : {no_sar_percentage_base}%\\n\")\n",
    "    # file.write(f\"Total correct: {zeroNoSarCT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3604e540-18e5-424e-91e7-b381db56ba64",
   "metadata": {
    "id": "3604e540-18e5-424e-91e7-b381db56ba64"
   },
   "outputs": [],
   "source": [
    "with open(\"SemEval2018_results_V1.txt\" ,\"a\") as file:\n",
    "    for x in range(len(outputs)) :\n",
    "        file.write (f\"\\n{outputs[x]} \\n- - - - - - - - - - - - - - - - - - - - - - - - - - - \\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
