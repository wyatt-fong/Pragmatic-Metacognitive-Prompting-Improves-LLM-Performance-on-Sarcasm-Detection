Pragmatic Metacognitive Prompting for Sarcasm Detection in LLMs
Overview
This repository explores the use of Pragmatic Metacognitive Prompting (PMP) to enhance the performance of Large Language Models (LLMs) in detecting sarcasm. Sarcasm detection is a challenging task in Natural Language Processing (NLP) due to its reliance on subtle cues that may not always be explicitly stated. By integrating pragmatic metacognitive strategies into the prompt engineering process, this approach aims to guide the model's reasoning and improve its ability to accurately identify sarcastic statements.

The repository includes code, experiments, and models that apply pragmatic metacognitive prompting to LLMs, providing insights and techniques for addressing sarcasm detection tasks.

Features
Pragmatic Metacognitive Prompting (PMP): A novel prompt engineering technique that encourages the model to reflect on and refine its understanding of context, enabling more nuanced and accurate responses.
Sarcasm Detection Dataset: A curated collection of sarcastic and non-sarcastic statements for training and evaluation.
LLM Integration: The repository supports fine-tuning or prompt-based usage of popular language models like GPT-3, GPT-4, or other large-scale transformers.
Evaluation Metrics: Metrics to assess the model's performance on sarcasm detection tasks, including accuracy, precision, recall, and F1 score.
